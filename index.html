<html>
	<head>
		<!-- Use the bootstrap as design reference -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
 		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
 		<script src="myscripts.js"></script>
 		<!-- Set character set to display latin characters -->
 		<meta charset="UTF-8">

 		<!-- Set author -->
 		 <meta name="author" content="Group 8">
 		 
 		<!-- Website title -->
		<title>Tutorial SPD</title>
	</head>

	<body>
		<!-- 
			Tópicos: Introdução, estrutura, narrativa, exemplos clássicos, erros (no meio da narrativa)
		-->
		<div class="container" style="width: 90%">
			<div class="row">
				<center>
					<div class="jumbotron">
						<!-- SECTION TITLE -->
						<h2>Introdução</h2>
					</div>
				</center>
			</div>
			<div class="row">
				<!-- MAIN NAVIGATION TAB -->
				<div class="col-sm-2">
					<nav class="container-fluid">
						<ul class="nav navbar-nav">
							<li><a href="index.html">O que é o OpenMP?</a></li>
							<br>

							<li class="active"><a href="tudo_pronto.html">Tudo pronto?</a></li>
							<br>

							<li><a href="diretivas.html">Diretivas</a></li>
							<br>

							<li><a href="clausulas.html">Cláusulas</a></li>
							<br>

							<li><a href="execucao.html">Bibliotecas de execução</a></li>
							<br>

							<li><a href="variaveis.html">Variáveis de ambiente</a></li>
							<br>

							<li><a href="exemplos.html">Exemplos clássicos</a></li>
							<br>

							<li><a href="erros.html">Erros frequentes</a></li>
							<br>
						</ul>
					</nav>
				</div>
				<!-- SECTION CONTENT -->
				<div class="col-sm-14">
					<p>
						O OpenMP (Open Multi-Processing), é uma interface de programação (API) portátil, usada para programação paralela com memória partilhada para arquiteturas de múltiplos processadores, para as linguagens de programação de C, C++ e Fortran. OpenMP implementa o uso de multithreading através do modelo “fork & join”. O openMP é composto por 3 componentes principais da API, sendo estes: diretivas de compilador, biblioteca de execução e variáveis de ambiente.
					</p>

					<div class="container-fluid">
						<h4>Vantagens:</h4>
						<ul>
							<li>Simples: não precisa lidar com a passagem de mensagens como acontece no Message Passing Interface (MPI), sendo mais fácil de usar e de corrigir em caso de bug do que MPI; </li>
							<li>Código multithreading portátil;</li>
							<li>Código fácil de ler e compreender;</li>
							<li>Diretivas podem ser adicionadas incrementalmente - paralelização incremental;</li>
							<li>As diretivas de compilador e as bibliotecas de execução são chamadas em comentário, tornando possível executar o programa em série utilizando compiladores sequenciais;</li>
							<li>Nenhuma ou pouca modificação (de fácil alteração) de instruções de código em série para instruções de código paralelo.</li>
						</ul>
						<br>
						<h4>Desvantagens:</h4>
						<ul>
							<li>Só é executado de forma eficiente em multiprocessadores com memória compartilhada;</li>
							<li>Necessita de um compilador que suporta OpenMP;</li>
							<li>Mais usado para paralelização de ciclos;</li>
							<li>A escalabilidade é limitada pela arquitetura de memória;</li>
							<li>Não está presente o tratamento de forma segura do erro.</li>
						</ul>
					</div>
					<div class="container-fluid">
						<h4>Pré-requisitos</h4>
						<p>
							Para este tutorial será necessário que o utilizador já tenha algumas noções sobre modelos de sistemas de programação paralela e linguagem em que irá programar (C/C++ ou Forthan). Resumidamente, os conceitos mais importantes são:
						</p>
						<div class="container-fluid">
							<ul>
								<li><b>Paralelismo baseado em threads:</b> Consiste na existência de um processo em que partilha memória entre múltiplos threads. Caso o processo termine, os threads deixam de existir.</li><br>
								<li><b>Paralelismo explícito:</b> O OpenMP é um recurso de programação paralela que dá ao programador total controlo sobre a paralelização do código, desde a simples inserção de diretivas de compiladores num programa que corre em série, até à inserção complexa de sub-rotinas para configurar vários níveis de paralelismo e locks.</li><br>
								<li><b>Modelo “Fork & Join”:</b> É um modelo de paralelização onde o “master thread” subdivide-se, através de fork, num número específico de “threads escravos”, sendo as tarefas divididas entre eles. Visto que os threads são executados simultaneamente, há momentos na execução do programa onde os “threads escravos” terminam e voltam apenas a um único thread, o “master thread”. Esse momento final que delimita o final da região em paralelo, denomina-se join.</li><br>
								<li><b>Baseado em diretivas de compilador:</b> No OpenMP, todo o paralelismo é definido através de diretivas de compilador.</li><br>
								<li><b>Suporta paralelismo recursivo:</b> O OpenMP permite a implementação de “nested parallelism”, ou seja, é possível a criação e execução de um sistema paralelo dentro de outro sistema paralelo.</li><br>
								<li><b>Threads dinâmicos:</b> O OpenMP permite a alteração do número de threads criadas durante a execução do programa.</li><br>
								<li><b>Suporte de “data scoping”:</b> O OpenMP permite ao programador especificar quando é que os dados/variáveis serão partilhados ou privados.</li><br>
							</ul>
						</div>

						<hr>

						<center><h3>Referências</h3></center>
						<div class="container-fluid">
						<table class="table">
							<thead><tr><th></th></tr></thead>
							<tbody>
								<tr>
									<td>Blaise Barney, L. L. (28 de Junho de 2018). OpenMP. Obtido em 26 de Outubro de 2018, de Lawrence Livermore National Laboratory: https://computing.llnl.gov/tutorials/openMP/</td>
								</tr>
								<tr>
									<td>Dartmouth College. (14 de Fevereiro de 2011). Pros and Cons of OpenMP/MPI. Obtido em 26 de Outubro de 2018, de Dartmouth College: https://www.dartmouth.edu/~rc/classes/intro_mpi/parallel_prog_compare.html#top</td>
								</tr>
								<tr><td>Desempenho, Universidade Estadual de Campinas & Centro Nacional de Processamento de Alto. (2014). Apostila de Treinamento: Introdução ao OpenMP. Obtido em 26 de Outubro de 2018, de OpenMP: https://www.cenapad.unicamp.br/servicos/treinamentos/apostilas/apostila_openmp.pdf</td></tr>
								<tr><td>Gonçalves, R. C. (28 de Setembro de 2014). PARALELIZAÇÃO DE APLICAÇÕES COM OPENMP | Revista PROGRAMAR. Obtido em 26 de Outubro de 2018, de Revista PROGRAMAR: https://www.revista-programar.info/artigos/paralelizacao-de-aplicacoes-com-openmp/</td></tr>
								<tr><td>IBM Knowledge Center. (s.d.). IBM Knowledge Center - Compiler Reference. Obtido em 26 de Outubro de 2018, de IBM Knowledge Center: https://www.ibm.com/support/knowledgecenter/SSGH2K_12.1.0/kc_gen/com.ibm.xlc121.aix.doc_toc-gen5.html</td></tr>
								<tr><td>Jr., D. R. (s.d.). ntroductory Examples for C. Obtido em 26 de 10 de 2018, de David Monismith: http://monismith.info/cs599/examples.html</td></tr>
								<tr><td>Julio Cesar Torelli, O. M. (2004). Programação paralela em SMPs com OpenMP e POSIX Threads: um estudo comparativo. Obtido em 26 de Outubro de 2018, de Universidade Federal do Rio Grande do Sul (UFRGS): http://www.niee.ufrgs.br/eventos/CBCOMP/2004/pdf/Sistemas_Paralelos_Distribuidos/t170100281_3.pdf</td></tr>
								<tr><td>Microsoft. (s.d.). OpenMP in Visual C++. Obtido em 26 de Outubro de 2018, de OpenMP in Visual C++: https://msdn.microsoft.com/pt-pt/library/tt15eb9t.aspx</td></tr>
								<tr><td>Paulo Penteado, I. /. (s.d.). Paralelização Introdução a vetorização, OpenMP e MPI. Obtido em 26 de Outubro de 2018, de OpenMP: http://www.ppenteado.net/ast/pp_para/pp_para_on_3.pdf</td></tr>
								<tr><td>Silva, F. (s.d.). Introdução ao OpenMP. Obtido em 26 de Outubro de 2018, de DEPARTAMENTO DE CIÊNCIA DE COMPUTADORES FACULDADE DE CIÊNCIAS DA UNIVERSIDADE DO PORTO: https://www.dcc.fc.up.pt/~fds/aulas/PPD/0708/intro_openmp-1x2.pdf</td></tr>
								<tr><td>TEXAS ADVANCED COMPUTING CENTER. (26 de Outubro de 2018). OpenMP topic: Loop parallelism. Obtido de TEXAS ADVANCED COMPUTING CENTER: http://pages.tacc.utexas.edu/~eijkhout/pcse/html/omp-loop.html</td></tr>
								<tr><td>Tim Mattson, L. M. (s.d.). A “Hands-on” Introduction to OpenMP. Obtido em 26 de Outubro de 2018, de OpenMP: https://www.openmp.org/wp-content/uploads/omp-hands-on-SC08.pdf</td></tr>
								<tr><td>UCLouvain. (s.d.). OpenMP* Run Time Library Routines. Obtido em 26 de Outubro de 2018, de Center for High Performance Computing and Mass Storage | UCLouvain: http://www.cism.ucl.ac.be/Equipements/Logiciels/Manuels/Intel/ic60/c_ug/linux168.html</td></tr>
								<tr><td>Wikipedia. (12 de Agosto de 2017). OpenMP. Obtido em 26 de Outubro de 2018, de Wikipedia: https://pt.wikipedia.org/wiki/OpenMP</td></tr>
								<tr>Wikipedia. (12 de Agosto de 2017). OpenMP. Obtido em 26 de Outubro de 2018, de Wikipedia: https://pt.wikipedia.org/wiki/OpenMP<td></td></tr>
							</tbody>
						</table>
					</div>
					</div>

				</div>
			</div>
		</div>

	</body>
</html>